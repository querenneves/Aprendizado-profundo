# -*- coding: utf-8 -*-
"""Semana 2 - Deep Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16ASGgCKfMA9YGKkkR5cCtLnaMpUgzNUW

# Pacotes
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import Model
import keras.datasets as kds

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.image import imread

print(tf.__version__)

"""# Dados"""

num_classes = 10
input_shape = (28, 28, 1)

# Carga dos dados (keras.datasets)
(x_train, y_train), (x_test, y_test) = kds.mnist.load_data()

# Normalização das features
x_train = x_train.astype("float32") / 255
x_test = x_test.astype("float32") / 255

# Conversão das classes em vetores one-hot-encoding
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

plt.figure(figsize=(10, 8))
for i in range(20):
  ax = plt.subplot(4, 5, i + 1)
  plt.imshow(x_test[i].reshape(28, 28))
  plt.gray()
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
plt.show()

"""# Modelo 01"""

# Modelo Linear (sem camada oculta)
modelo1 = keras.Sequential()
modelo1.add(keras.layers.Flatten(input_shape=input_shape))
modelo1.add(keras.layers.Dense(units=10, activation="softmax"))
modelo1.summary()

#Grafo da rede gerada
tf.keras.utils.plot_model(modelo1, show_shapes=True)

modelo1.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

#treinamento
history = modelo1.fit(x_train, y_train, batch_size=256, epochs=30, validation_split=0.2, verbose=2)

plt.xlabel("Épocas'")
plt.ylabel("Loss")
plt.plot(history.history["loss"], label="Treino")
plt.plot(history.history["val_loss"], label="Val")
plt.legend()
plt.show()

# Avaliação do modelo treinado no conjunto de teste
print("Avaliação do modelo (Teste)")
results = modelo1.evaluate(x_test, y_test, batch_size=1000)
print("Test loss, Test acc:", results)

"""# Modelo 02 - MLP"""

modelo2 = keras.Sequential()
modelo2.add(keras.layers.Flatten(input_shape=input_shape))
modelo2.add(keras.layers.Dense(units=100, activation="relu"))
modelo2.add(keras.layers.Dense(units=10, activation="softmax"))
modelo2.summary()

#Grafo da rede gerada
tf.keras.utils.plot_model(modelo2, show_shapes=True)

modelo2.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
history = modelo2.fit(x_train, y_train, batch_size=256, epochs=30, validation_split=0.2, verbose=2)

plt.xlabel("Épocas'")
plt.ylabel("Loss")
plt.plot(history.history["loss"], label="Treino")
plt.plot(history.history["val_loss"], label="Val")
plt.legend()
plt.show()

# Avaliação do modelo treinado no conjunto de tete
print("Avaliação do modelo (Teste)")
results = modelo2.evaluate(x_test, y_test)
print("Test loss, Test acc:", results)

"""# Modelo 3 - CNN"""

modelo3 = keras.Sequential(
        [
        keras.Input(shape=input_shape),
        keras.layers.Conv2D(5, kernel_size=(3, 3), activation="relu"),
        keras.layers.MaxPooling2D(pool_size=(2, 2)),
        keras.layers.Conv2D(10, kernel_size=(3, 3), activation="relu"),
        keras.layers.MaxPooling2D(pool_size=(2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(num_classes, activation="softmax"),
  ]
)
modelo3.summary()

modelo3.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
history = modelo3.fit(x_train, y_train, batch_size=256, epochs=30, validation_split=0.2, verbose=2)

plt.xlabel("Épocas'")
plt.ylabel("Loss")
plt.plot(history.history['loss'], label="Treino")
plt.plot(history.history['val_loss'], label="Val")
plt.legend()
plt.show()

# Avaliação do modelo treinado no conjunto de tete
print("Avaliação do modelo (Teste)")
results = modelo3.evaluate(x_test, y_test, batch_size=1000)
print("Test loss, Test acc:", results)

"""# Transfer Learning

## Carregamento do Modelo Inception V3
"""

from tensorflow.keras.applications import InceptionV3, ResNet50V2
inception = InceptionV3(
     input_shape=(150, 150, 3), include_top=False, weights="imagenet")

"""## Congelamento das Camadas (extrator)"""

for layer in inception.layers:
  layer.trainable = False

last_layer = inception.get_layer('mixed7')
last_output = last_layer.output
print('Dimensões da última camada da rede:', last_output.shape)

"""## Construção do Modelo (Classificação Binária)"""

# Flattening da última camada convolucional
x = layers.Flatten()(last_output)
# Camada densa com 512 neurônios
x = layers.Dense(512, activation='relu')(x)
# Dropout de 0.2
x = layers.Dropout(0.2)(x)
# Neurônio de saída - classificação binária
x = layers.Dense(1, activation='sigmoid')(x)

# Criação do modelo:
modelo4 = Model(inception.input, x)

modelo4.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['acc'])

for layer in modelo4.layers:
  print(layer, layer.trainable)

tf.keras.utils.plot_model(modelo4, show_shapes=True)

"""## Carga do dataset Cats & Dogs"""

!wget --no-check-certificate \
  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O \
  /tmp/cats_and_dogs_filtered.zip

"""## Preparação do conjunto para treinamento"""

import os
import zipfile

from tensorflow.keras.preprocessing.image import ImageDataGenerator

local_zip = '/tmp/cats_and_dogs_filtered.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

# Define our example directories and files
base_dir = '/tmp/cats_and_dogs_filtered'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# Directory with our training cat pictures
train_cats_dir = os.path.join(train_dir, 'cats')

# Directory with our training dog pictures
train_dogs_dir = os.path.join(train_dir, 'dogs')

# Directory with our validation cat pictures
validation_cats_dir = os.path.join(validation_dir, 'cats')

# Directory with our validation dog pictures
validation_dogs_dir = os.path.join(validation_dir, 'dogs')

train_cat_fnames = os.listdir(train_cats_dir)
train_dog_fnames = os.listdir(train_dogs_dir)

# Add our data-augmentation parameters to ImageDataGenerator
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)

# Note that the validation data should not be augmented!
val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        train_dir, # This is the source directory for training images
        target_size=(150, 150),  # All images will be resized to 150x150
        batch_size=20,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='binary')

# Flow validation images in batches of 20 using val_datagen generator
validation_generator = val_datagen.flow_from_directory(
        validation_dir,
        target_size=(150, 150),
        batch_size=20,
        class_mode='binary')

"""# Imagens de Gatos"""

# Imagens de Gatos

plt.figure(figsize=(10, 10))
for i in range(16):
  ax = plt.subplot(4, 4, i + 1)
  filename = train_cats_dir + '/cat.' + str(i) + '.jpg'
  image = imread(filename)
  plt.imshow(image)
  ax.get_xaxis().set_visible(False)
  ax.get_yaxis().set_visible(False)
plt.show()

"""## Treinamento do Modelo (camadas finais)

FC - Fully Connected Layers
"""

history = modelo4.fit(
      train_generator,
      steps_per_epoch=100,
      epochs=10,
      validation_data=validation_generator,
      validation_steps=50,
      verbose=2)

# Get training and validation metrics from the history object
acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

# number of epochs
epochs = range(len(acc))

plt.plot(epochs, acc, label="Acc")
plt.plot(epochs, val_acc, label="Val Acc")
plt.title('Acurácia de treino e validação')
plt.legend()

plt.figure()

plt.plot(epochs, loss, label="Treino")
plt.plot(epochs, val_loss, label="Validacao")
plt.title('Loss treino e validação')
plt.legend()
plt.show()